summary(prova)
library(CausalArima)
CausalArima<-function(y, auto = TRUE, order = c(0, 0, 0), seasonal = c(0, 0, 0), ic = "aic", xreg = NULL, dates,
int.date, arima.args = list(), auto.args = list(), nboot = NULL, alpha = 0.05){
browser()
### param checks
if(class(y) != "ts" & !is.numeric(y)) stop("y must be numeric or ts")
if(is.numeric(y)){
y <- ts(y, frequency = findfrequency(y))
}
if(!missing(xreg)) {
if(!is.matrix(xreg) && !is.data.frame(xreg) && !is.numeric(xreg))
stop("`xreg` must be a numeric vector, matrix or data.frame")
xreg <- as.matrix(xreg)
if(nrow(xreg) != length(y)) stop("nrow(xreg) != length(y)")
}
if(!any(class(dates) %in% c("Date", "POSIXct", "POSIXlt", "POSIXt")))
stop("`dates` must be a vector of class Date")
if(length(dates) != length(y)) stop("length(dates) != length(y)")
if(length(int.date) != 1 || !any(class(dates) %in% c("Date", "POSIXct", "POSIXlt", "POSIXt")))
stop("`int.date` must be a Date of length 1")
if(!missing(nboot) && (!is.numeric(nboot) | nboot <= 0)) stop("`nboot` must be a positive numeric value")
if(auto && sum(sum(order), sum(seasonal)) > 0){auto <- FALSE}
### STEP 1. Subsetting the data: before and after the intervention date
ind<-dates>=int.date
y.00<-y[!ind]
y.01<-y[ind]
if(!is.null(xreg)) {
xreg0<-xreg[!ind,]
xreg1<-xreg[ind,]
} else {
xreg0 <- NULL
xreg1 <- NULL
}
### STEP 2. Model estimation in the pre-intervention period
if(auto){
model <- do.call("auto.arima", c(list(y = y.00),
list(ic = ic), list(xreg = xreg0), auto.args))
} else {
model <- do.call("Arima", c(list(y = y.00),
list(order = order), list(seasonal = seasonal), list(xreg = xreg0),
arima.args))
}
### STEP 3. Forecasting the counterfactual outcome in the absence of intervention
h<-length(y.01)
fcast<-forecast(model, xreg = xreg1, h = h, level = 1-alpha)
mean.fcast.0<-as.numeric(fcast$mean)
forecasted_low<-as.numeric(fcast$lower)
forecasted_up<-as.numeric(fcast$upper)
### STEP 4. Causal effect computation: direct comparison between the observed outcome (y.01) and the
#           predicted counterfactual (mean.fcast.0)
causal.effect.0 <- y.01 - mean.fcast.0
### STEP 5. Test statistics
## Extracting
d <- model$arma[6]; D <- model$arma[7]; S <- model$arma[5]
coef <- model$coef
sig2 <- model$sigma2
ar  <- coef[ substr(names(coef), 1, 2) == "ar"  ]
ma  <- coef[ substr(names(coef), 1, 2) == "ma"  ]
sar <- coef[ substr(names(coef), 1, 3) == "sar" ]
sma <- coef[ substr(names(coef), 1, 3) == "sma" ]
## MA(inf)
par <- .sarma2larma(ar = ar, ma = ma, sar = sar, sma = sma, S = S)
psi <- c(1, ARMAtoMA(ar = par$ar, ma = par$ma, lag.max = h-1))
## Stats (tau, sum.tau, avg.tau)
# Removing NA's
psi <- psi[!is.na(causal.effect.0)]
tau  <- causal.effect.0[!is.na(causal.effect.0)]
sum.tau <- cumsum(tau)
avg.tau <- cumsum(tau) / seq(1, length(tau), 1)
# Gaussian based inference
norm <- .norm.inf(stat1 = tau, stat2 = sum.tau, stat3 = avg.tau, sig2 = sig2, psi = psi)
# Bootstrap based inference
boot <- if ( NROW(nboot) > 0 && is.finite(nboot) && nboot >= 1)
{
nboot <- round(nboot[1])
.boot.inf(model = model, h = h, nboot = nboot, y.01 = y.01, xreg = xreg1)
}
else
{
NULL
}
### STEP 6. Saving results
my_list <- list(norm = norm, boot = boot, causal.effect = causal.effect.0, model = model,
dates = dates, int.date = int.date, y = y, xreg = xreg, forecast = mean.fcast.0, forecast_lower=forecasted_low,
forecast_upper = forecasted_up, alpha=alpha)
class(my_list) <- "cArima"
return(my_list)
}
# ------------------------------------------------------------------------------
##################################################################################
## Merge AR(p) and SAR(P); the same for MA(q) and SMA(Q)
##################################################################################
.sarma2larma <- function(ar = NULL, ma = NULL, sar = NULL, sma = NULL, S = 12)
{
#### Adjust
if ( NROW(ar) > 0 ) { ar <- -ar }
if ( NROW(sar) > 0 ) { sar <- -sar }
#### model
list(
ar = -.long(p = ar, ps = sar, s = S),
ma =  .long(p = ma, ps = sma, s = S) )
}
##################################################################################
## Merge short and seasonal components
##################################################################################
.long <- function(p, ps, s)
{
#### Settings
np  <- NROW( p )
nps <- NROW( ps )
####
cp  <- if ( np > 0 ) { c(1, p) } else { 1 }
cps <- if ( nps > 0 )
{
ind <- seq(from = s, by = s, length.out = nps)
x1 <- numeric(s * nps)
x1[ind] <- ps
c(1, x1)
}
else
{
1
}
#### Answer
convolve(cp, rev(cps), type = "open")[-1]
}
##################################################################################
## Compute variance of the point, cumulative and temporal average effect
##################################################################################
.norm.inf <- function(stat1, stat2, stat3, sig2, psi)
{
#### Settings
np <- NROW(psi)
## Stat 1: tau ~ Normal
psi1 <- psi
sd1  <- sqrt(sig2 * cumsum(psi^2))
z1 <- (stat1 - 0) / sd1
## Stat 2: delta ~ Normal
psi2 <- cumsum(psi)
sd2  <- sqrt(sig2 * cumsum(psi2^2))
z2 <- (stat2 - 0) / sd2
## Stat 3: avg.tau ~ Normal
sd3 <- sd2 / seq(1, np, 1)
z3 <- (stat3 - 0) / sd3
#### Gaussian based inference
inf <- cbind(
tau = stat1, sd.tau = sd1,
pvalue.tau.l = pnorm(z1), pvalue.tau.b = 2 * (1 - pnorm(abs(z1))), pvalue.tau.r = 1 - pnorm(z1),
sum = stat2, sd.sum = sd2,
pvalue.sum.l = pnorm(z2), pvalue.sum.b = 2 * (1 - pnorm(abs(z2))), pvalue.sum.r = 1 - pnorm(z2),
avg = stat3, sd.avg = sd3,
pvalue.avg.l = pnorm(z3), pvalue.avg.b = 2 * (1 - pnorm(abs(z3))), pvalue.avg.r = 1 - pnorm(z3))
#### Answer
list(type = "norm", inf = inf)
}
# ------------------------------------------------------------------------------
.boot.inf <- function(model, h, nboot, y.01, xreg){
### Generating bootstrap simulations
simulated <- matrix(NA, h, nboot)
for(i in 1:nboot){
simulated[,i] <- simulate(model,  future = TRUE, nsim = h, xreg = xreg, bootstrap = TRUE)
}
### stat1
# removing rows corresponding to missing obs in y.01
dist1 <- y.01 - simulated
dist1 <- dist1[-which(is.na(y.01)), ]
stat1 <- rowMeans(dist1)
sd1  <- apply(dist1, 1, sd)
pv1.l <- apply(dist1, 1, FUN = function(x)(mean(x > 0)))
pv1.b <- apply(dist1, 1, FUN = function(x)(2-2*max(mean(x < 0), mean(x > 0))))
pv1.r <- apply(dist1, 1, FUN = function(x)(mean(x < 0)))
### stat2
dist2 <- apply(dist1, 2, cumsum)
stat2 <- rowMeans(dist2)
sd2 <- apply(dist2, 1, sd)
pv2.l <- apply(dist2, 1, FUN = function(x)(mean(x > 0)))
pv2.b <- apply(dist2, 1, FUN = function(x)(2-2*max(mean(x < 0), mean(x > 0))))
pv2.r <- apply(dist2, 1, FUN = function(x)(mean(x < 0)))
### stat3
dist3 <- apply(dist2, 2, FUN = function(x)(x/seq(1, dim(dist2)[1], 1)))
stat3 <- rowMeans(dist3)
sd3 <- apply(dist3, 1, sd)
pv3.l <- apply(dist3, 1, FUN = function(x)(mean(x > 0)))
pv3.b <- apply(dist3, 1, FUN = function(x)(2-2*max(mean(x < 0), mean(x > 0))))
pv3.r <- apply(dist3, 1, FUN = function(x)(mean(x < 0)))
#### Bootstrap based inference
inf <- cbind(
tau = stat1, sd.tau = sd1,
pvalue.tau.l = pv1.l, pvalue.tau.b = pv1.b, pvalue.tau.r = pv1.r,
sum = stat2, sd.sum = sd2,
pvalue.sum.l = pv2.l, pvalue.sum.b = pv2.b, pvalue.sum.r = pv2.r,
avg = stat3, sd.avg = sd3,
pvalue.avg.l = pv3.l, pvalue.avg.b = pv3.b, pvalue.avg.r = pv3.r)
#### Answer
list(type = "boot", inf = inf, boot.distrib = simulated)
}
length(y)
ce <- CausalArima(y = ts(y, frequency = 7), xreg = xreg, int.date = int.date,
dates = dates, nboot = 1000)
class(y)
y <- ts(y, frequency = 7)
class(y)
is.ts(y)
is.numeric(y)
y <- sales[,2]
is.ts(y)
if(!is.ts(y) & !is.numeric(y)){print("stop")}
CausalArima<-function(y, auto = TRUE, order = c(0, 0, 0), seasonal = c(0, 0, 0), ic = "aic", xreg = NULL, dates,
int.date, arima.args = list(), auto.args = list(), nboot = NULL, alpha = 0.05){
browser()
### param checks
if(class(y) != "ts" & !is.numeric(y)) stop("y must be numeric or ts")
if(!is.ts(y)){
y <- ts(y, frequency = findfrequency(y))
}
if(!missing(xreg)) {
if(!is.matrix(xreg) && !is.data.frame(xreg) && !is.numeric(xreg))
stop("`xreg` must be a numeric vector, matrix or data.frame")
xreg <- as.matrix(xreg)
if(nrow(xreg) != length(y)) stop("nrow(xreg) != length(y)")
}
if(!any(class(dates) %in% c("Date", "POSIXct", "POSIXlt", "POSIXt")))
stop("`dates` must be a vector of class Date")
if(length(dates) != length(y)) stop("length(dates) != length(y)")
if(length(int.date) != 1 || !any(class(dates) %in% c("Date", "POSIXct", "POSIXlt", "POSIXt")))
stop("`int.date` must be a Date of length 1")
if(!missing(nboot) && (!is.numeric(nboot) | nboot <= 0)) stop("`nboot` must be a positive numeric value")
if(auto && sum(sum(order), sum(seasonal)) > 0){auto <- FALSE}
### STEP 1. Subsetting the data: before and after the intervention date
ind<-dates>=int.date
y.00<-y[!ind]
y.01<-y[ind]
if(!is.null(xreg)) {
xreg0<-xreg[!ind,]
xreg1<-xreg[ind,]
} else {
xreg0 <- NULL
xreg1 <- NULL
}
### STEP 2. Model estimation in the pre-intervention period
if(auto){
model <- do.call("auto.arima", c(list(y = y.00),
list(ic = ic), list(xreg = xreg0), auto.args))
} else {
model <- do.call("Arima", c(list(y = y.00),
list(order = order), list(seasonal = seasonal), list(xreg = xreg0),
arima.args))
}
### STEP 3. Forecasting the counterfactual outcome in the absence of intervention
h<-length(y.01)
fcast<-forecast(model, xreg = xreg1, h = h, level = 1-alpha)
mean.fcast.0<-as.numeric(fcast$mean)
forecasted_low<-as.numeric(fcast$lower)
forecasted_up<-as.numeric(fcast$upper)
### STEP 4. Causal effect computation: direct comparison between the observed outcome (y.01) and the
#           predicted counterfactual (mean.fcast.0)
causal.effect.0 <- y.01 - mean.fcast.0
### STEP 5. Test statistics
## Extracting
d <- model$arma[6]; D <- model$arma[7]; S <- model$arma[5]
coef <- model$coef
sig2 <- model$sigma2
ar  <- coef[ substr(names(coef), 1, 2) == "ar"  ]
ma  <- coef[ substr(names(coef), 1, 2) == "ma"  ]
sar <- coef[ substr(names(coef), 1, 3) == "sar" ]
sma <- coef[ substr(names(coef), 1, 3) == "sma" ]
## MA(inf)
par <- .sarma2larma(ar = ar, ma = ma, sar = sar, sma = sma, S = S)
psi <- c(1, ARMAtoMA(ar = par$ar, ma = par$ma, lag.max = h-1))
## Stats (tau, sum.tau, avg.tau)
# Removing NA's
psi <- psi[!is.na(causal.effect.0)]
tau  <- causal.effect.0[!is.na(causal.effect.0)]
sum.tau <- cumsum(tau)
avg.tau <- cumsum(tau) / seq(1, length(tau), 1)
# Gaussian based inference
norm <- .norm.inf(stat1 = tau, stat2 = sum.tau, stat3 = avg.tau, sig2 = sig2, psi = psi)
# Bootstrap based inference
boot <- if ( NROW(nboot) > 0 && is.finite(nboot) && nboot >= 1)
{
nboot <- round(nboot[1])
.boot.inf(model = model, h = h, nboot = nboot, y.01 = y.01, xreg = xreg1)
}
else
{
NULL
}
### STEP 6. Saving results
my_list <- list(norm = norm, boot = boot, causal.effect = causal.effect.0, model = model,
dates = dates, int.date = int.date, y = y, xreg = xreg, forecast = mean.fcast.0, forecast_lower=forecasted_low,
forecast_upper = forecasted_up, alpha=alpha)
class(my_list) <- "cArima"
return(my_list)
}
# ------------------------------------------------------------------------------
##################################################################################
## Merge AR(p) and SAR(P); the same for MA(q) and SMA(Q)
##################################################################################
.sarma2larma <- function(ar = NULL, ma = NULL, sar = NULL, sma = NULL, S = 12)
{
#### Adjust
if ( NROW(ar) > 0 ) { ar <- -ar }
if ( NROW(sar) > 0 ) { sar <- -sar }
#### model
list(
ar = -.long(p = ar, ps = sar, s = S),
ma =  .long(p = ma, ps = sma, s = S) )
}
##################################################################################
## Merge short and seasonal components
##################################################################################
.long <- function(p, ps, s)
{
#### Settings
np  <- NROW( p )
nps <- NROW( ps )
####
cp  <- if ( np > 0 ) { c(1, p) } else { 1 }
cps <- if ( nps > 0 )
{
ind <- seq(from = s, by = s, length.out = nps)
x1 <- numeric(s * nps)
x1[ind] <- ps
c(1, x1)
}
else
{
1
}
#### Answer
convolve(cp, rev(cps), type = "open")[-1]
}
##################################################################################
## Compute variance of the point, cumulative and temporal average effect
##################################################################################
.norm.inf <- function(stat1, stat2, stat3, sig2, psi)
{
#### Settings
np <- NROW(psi)
## Stat 1: tau ~ Normal
psi1 <- psi
sd1  <- sqrt(sig2 * cumsum(psi^2))
z1 <- (stat1 - 0) / sd1
## Stat 2: delta ~ Normal
psi2 <- cumsum(psi)
sd2  <- sqrt(sig2 * cumsum(psi2^2))
z2 <- (stat2 - 0) / sd2
## Stat 3: avg.tau ~ Normal
sd3 <- sd2 / seq(1, np, 1)
z3 <- (stat3 - 0) / sd3
#### Gaussian based inference
inf <- cbind(
tau = stat1, sd.tau = sd1,
pvalue.tau.l = pnorm(z1), pvalue.tau.b = 2 * (1 - pnorm(abs(z1))), pvalue.tau.r = 1 - pnorm(z1),
sum = stat2, sd.sum = sd2,
pvalue.sum.l = pnorm(z2), pvalue.sum.b = 2 * (1 - pnorm(abs(z2))), pvalue.sum.r = 1 - pnorm(z2),
avg = stat3, sd.avg = sd3,
pvalue.avg.l = pnorm(z3), pvalue.avg.b = 2 * (1 - pnorm(abs(z3))), pvalue.avg.r = 1 - pnorm(z3))
#### Answer
list(type = "norm", inf = inf)
}
# ------------------------------------------------------------------------------
.boot.inf <- function(model, h, nboot, y.01, xreg){
### Generating bootstrap simulations
simulated <- matrix(NA, h, nboot)
for(i in 1:nboot){
simulated[,i] <- simulate(model,  future = TRUE, nsim = h, xreg = xreg, bootstrap = TRUE)
}
### stat1
# removing rows corresponding to missing obs in y.01
dist1 <- y.01 - simulated
dist1 <- dist1[-which(is.na(y.01)), ]
stat1 <- rowMeans(dist1)
sd1  <- apply(dist1, 1, sd)
pv1.l <- apply(dist1, 1, FUN = function(x)(mean(x > 0)))
pv1.b <- apply(dist1, 1, FUN = function(x)(2-2*max(mean(x < 0), mean(x > 0))))
pv1.r <- apply(dist1, 1, FUN = function(x)(mean(x < 0)))
### stat2
dist2 <- apply(dist1, 2, cumsum)
stat2 <- rowMeans(dist2)
sd2 <- apply(dist2, 1, sd)
pv2.l <- apply(dist2, 1, FUN = function(x)(mean(x > 0)))
pv2.b <- apply(dist2, 1, FUN = function(x)(2-2*max(mean(x < 0), mean(x > 0))))
pv2.r <- apply(dist2, 1, FUN = function(x)(mean(x < 0)))
### stat3
dist3 <- apply(dist2, 2, FUN = function(x)(x/seq(1, dim(dist2)[1], 1)))
stat3 <- rowMeans(dist3)
sd3 <- apply(dist3, 1, sd)
pv3.l <- apply(dist3, 1, FUN = function(x)(mean(x > 0)))
pv3.b <- apply(dist3, 1, FUN = function(x)(2-2*max(mean(x < 0), mean(x > 0))))
pv3.r <- apply(dist3, 1, FUN = function(x)(mean(x < 0)))
#### Bootstrap based inference
inf <- cbind(
tau = stat1, sd.tau = sd1,
pvalue.tau.l = pv1.l, pvalue.tau.b = pv1.b, pvalue.tau.r = pv1.r,
sum = stat2, sd.sum = sd2,
pvalue.sum.l = pv2.l, pvalue.sum.b = pv2.b, pvalue.sum.r = pv2.r,
avg = stat3, sd.avg = sd3,
pvalue.avg.l = pv3.l, pvalue.avg.b = pv3.b, pvalue.avg.r = pv3.r)
#### Answer
list(type = "boot", inf = inf, boot.distrib = simulated)
}
ce <- CausalArima(y = ts(y, frequency = 7), xreg = xreg, int.date = int.date,
dates = dates, nboot = 1000)
summary(model)
frequency(y.00)
frequency(y)
ce <- CausalArima(y = ts(y, frequency = 7), xreg = xreg, int.date = int.date,
dates = dates, nboot = 1000)
class(y)
class(y.00)
class(y[!ind])
head(y)
head(y.00)
prova <- ts(y[!ind], frequency = frequency(y))
class(prova)
head(prova)
CausalArima<-function(y, auto = TRUE, order = c(0, 0, 0), seasonal = c(0, 0, 0), ic = "aic", xreg = NULL, dates,
int.date, arima.args = list(), auto.args = list(), nboot = NULL, alpha = 0.05){
browser()
### param checks
if(class(y) != "ts" & !is.numeric(y)) stop("y must be numeric or ts")
if(!is.ts(y)){
y <- ts(y, frequency = findfrequency(y))
}
if(!missing(xreg)) {
if(!is.matrix(xreg) && !is.data.frame(xreg) && !is.numeric(xreg))
stop("`xreg` must be a numeric vector, matrix or data.frame")
xreg <- as.matrix(xreg)
if(nrow(xreg) != length(y)) stop("nrow(xreg) != length(y)")
}
if(!any(class(dates) %in% c("Date", "POSIXct", "POSIXlt", "POSIXt")))
stop("`dates` must be a vector of class Date")
if(length(dates) != length(y)) stop("length(dates) != length(y)")
if(length(int.date) != 1 || !any(class(dates) %in% c("Date", "POSIXct", "POSIXlt", "POSIXt")))
stop("`int.date` must be a Date of length 1")
if(!missing(nboot) && (!is.numeric(nboot) | nboot <= 0)) stop("`nboot` must be a positive numeric value")
if(auto && sum(sum(order), sum(seasonal)) > 0){auto <- FALSE}
### STEP 1. Subsetting the data: before and after the intervention date
ind<-dates>=int.date
y.00<-ts(y[!ind], frequency = frequency(y))
y.01<-ts(y[ind], frequency = frequency(y))
if(!is.null(xreg)) {
xreg0<-xreg[!ind,]
xreg1<-xreg[ind,]
} else {
xreg0 <- NULL
xreg1 <- NULL
}
### STEP 2. Model estimation in the pre-intervention period
if(auto){
model <- do.call("auto.arima", c(list(y = y.00),
list(ic = ic), list(xreg = xreg0), auto.args))
} else {
model <- do.call("Arima", c(list(y = y.00),
list(order = order), list(seasonal = seasonal), list(xreg = xreg0),
arima.args))
}
### STEP 3. Forecasting the counterfactual outcome in the absence of intervention
h<-length(y.01)
fcast<-forecast(model, xreg = xreg1, h = h, level = 1-alpha)
mean.fcast.0<-as.numeric(fcast$mean)
forecasted_low<-as.numeric(fcast$lower)
forecasted_up<-as.numeric(fcast$upper)
### STEP 4. Causal effect computation: direct comparison between the observed outcome (y.01) and the
#           predicted counterfactual (mean.fcast.0)
causal.effect.0 <- y.01 - mean.fcast.0
### STEP 5. Test statistics
## Extracting
d <- model$arma[6]; D <- model$arma[7]; S <- model$arma[5]
coef <- model$coef
sig2 <- model$sigma2
ar  <- coef[ substr(names(coef), 1, 2) == "ar"  ]
ma  <- coef[ substr(names(coef), 1, 2) == "ma"  ]
sar <- coef[ substr(names(coef), 1, 3) == "sar" ]
sma <- coef[ substr(names(coef), 1, 3) == "sma" ]
## MA(inf)
par <- .sarma2larma(ar = ar, ma = ma, sar = sar, sma = sma, S = S)
psi <- c(1, ARMAtoMA(ar = par$ar, ma = par$ma, lag.max = h-1))
## Stats (tau, sum.tau, avg.tau)
# Removing NA's
psi <- psi[!is.na(causal.effect.0)]
tau  <- causal.effect.0[!is.na(causal.effect.0)]
sum.tau <- cumsum(tau)
avg.tau <- cumsum(tau) / seq(1, length(tau), 1)
# Gaussian based inference
norm <- .norm.inf(stat1 = tau, stat2 = sum.tau, stat3 = avg.tau, sig2 = sig2, psi = psi)
# Bootstrap based inference
boot <- if ( NROW(nboot) > 0 && is.finite(nboot) && nboot >= 1)
{
nboot <- round(nboot[1])
.boot.inf(model = model, h = h, nboot = nboot, y.01 = y.01, xreg = xreg1)
}
else
{
NULL
}
### STEP 6. Saving results
my_list <- list(norm = norm, boot = boot, causal.effect = causal.effect.0, model = model,
dates = dates, int.date = int.date, y = y, xreg = xreg, forecast = mean.fcast.0, forecast_lower=forecasted_low,
forecast_upper = forecasted_up, alpha=alpha)
class(my_list) <- "cArima"
return(my_list)
}
# ------------------------------------------------------------------------------
ce <- CausalArima(y = ts(y, frequency = 7), xreg = xreg, int.date = int.date,
dates = dates, nboot = 1000)
summary(model)
ce <- CausalArima(y = y, xreg = xreg, int.date = int.date,
dates = dates, nboot = 1000)
summary(model)
